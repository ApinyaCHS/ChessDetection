{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"colab":{"provenance":[],"collapsed_sections":["XCr9fJRmbyGQ","SVUNRH4mYHiE","jFLMALCGffKv","wiHDnPAYkw_T","VFvMrBM3I7Lt","IGjWg8_0k4Ae","OwJjhrLICF09","jwsDGFHO1i2G","r4XylqbGchnd","8oJu-PoHHunY","snHkIoX61b86","Bx5DPKQGcQ21","68q15miN3_9C"],"gpuType":"T4","toc_visible":true},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":83828,"databundleVersionId":9597345,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Chess Move PGN Tracking","metadata":{"id":"eUJpOr2iBv7t"}},{"cell_type":"code","source":"!pip install -U ultralytics==8.3.40 --quiet","metadata":{"id":"QVxigtL8ARde"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from google.colab import drive\ndrive.mount(\"/content/drive\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mgw6cOojGKch","outputId":"df735600-04a1-440e-8644-0fd101b9fad7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"execution_count":null},{"cell_type":"code","source":"import csv\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport pandas as pd\nimport re\nimport shutil\nimport ultralytics\nimport warnings\nfrom IPython.display import Video\ntry:\n    from PIL import Image\nexcept ImportError:\n    import Image\nfrom ultralytics import YOLO","metadata":{"id":"eOP9KB-oArwk"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")","metadata":{"id":"P2VxglduyyZH"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Hand Detection","metadata":{"id":"XCr9fJRmbyGQ"}},{"cell_type":"code","source":"def detect_hand(model_hand, image):\n    results = model_hand.predict(\n        image,\n        imgsz=288,\n        conf=0.5,\n        classes=0 # Dectect only person class\n    )\n\n    # Access results for the first image\n    result_0 = results[0]\n\n    # Get bounding boxes\n    boxes = result_0.boxes  # Contains bounding boxes, confidences, and class IDs\n\n    hand_detection = False\n    if boxes is None or len(boxes) == 0:\n        print(\"No hand detection found\")\n    else:\n        for box in boxes:\n            # Get the box with the highest confidence\n            best_box = boxes[0]\n\n            # Extract bounding box details\n            xmin, ymin, xmax, ymax = best_box.xyxy.cpu().numpy().flatten()\n            conf = best_box.conf.cpu().numpy().item()\n            # cls = best_box.cls.cpu().numpy().item()\n\n            area_detected_hand = (xmax - xmin) * (ymax - ymin)\n            cutoff_area = (1080 * 0.2) * (1080 * 0.2) # 20% of Original Image Size\n            if area_detected_hand >= cutoff_area:\n                # Visualize the selected box on the image\n                test_image = result_0.plot()\n                image_rgb = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n                plt.imshow(image_rgb)\n                plt.axis(\"off\")\n                plt.show()\n                print(f\"Hand detection found with {conf:.4f}\")\n                hand_detection = True\n            else:\n                print(\"No hand detection found\")\n\n    return hand_detection","metadata":{"id":"RzTZOxM8b1py"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Chess Tracking","metadata":{"id":"SVUNRH4mYHiE"}},{"cell_type":"markdown","source":"### Get image persepective and centroid of board","metadata":{"id":"CVgjA1dJG2M9"}},{"cell_type":"code","source":"class ImageProcessor:\n    def __init__(self, image_paths, block_size=41, C=2):\n        \"\"\"\n        Initialize the image processor.\n\n        Args:\n            image_paths (list): List of image file paths.\n            block_size (int): Block size for adaptive thresholding.\n            C (int): Constant to subtract for adaptive thresholding.\n        \"\"\"\n        self.image_paths = image_paths\n        self.block_size = block_size\n        self.C = C\n        self.titles = [f'Board {i}' for i in range(1, len(image_paths) + 1)]\n\n    def process_images(self):\n        \"\"\"Processes and displays all images.\"\"\"\n        plt.figure(figsize=(12, 8))\n        for i, path in enumerate(self.image_paths):\n            img = self._read_image(path)\n            scanned = self._process_single_image(img)\n            if scanned is not None:\n                plt.subplot(3, 4, i + 1)\n                plt.title(self.titles[i])\n                plt.imshow(scanned, cmap=\"gray\")\n                plt.axis(\"off\")\n        plt.show()\n\n    def _read_image(self, path):\n        \"\"\"\n        Reads an image from the given path.\n\n        Args:\n            path (str): Path to the image file.\n\n        Returns:\n            img (numpy.ndarray): The read image.\n        \"\"\"\n        img = cv2.imread(path)\n        if img is None:\n            print(f\"Error reading image: {path}\")\n            return None, None\n        return img\n\n    def _process_single_image(self, img, return_with_grid=True):\n        \"\"\"\n        Processes a single image in memory.\n\n        Args:\n            img (numpy.ndarray): The input image.\n\n        Returns:\n            numpy.ndarray: The processed and warped image, or None if processing fails.\n        \"\"\"\n        orig = img.copy()\n        if img is None or orig is None:\n            print(\"Invalid image data provided.\")\n            return None\n\n        img_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        gray = cv2.cvtColor(img_RGB, cv2.COLOR_RGB2GRAY)\n        thresholded = self._threshold_image(gray)\n        edges = cv2.adaptiveThreshold(\n            thresholded, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, self.block_size, self.C\n        )\n        contours = self._find_contours(edges)\n\n        approxs = self._filter_quadrilaterals(contours)\n        points = self._extract_points(approxs)\n        if points is None or points.size == 0:\n            return None\n\n        paper_contour = self._find_paper_contour(contours)\n        if paper_contour is not None:\n            M, warped, complete_grid = self._warp_perspective(orig, paper_contour, points)\n\n            if return_with_grid:\n                return self._draw_grid(warped, complete_grid)\n            return M, warped, complete_grid\n\n        return None\n\n    def _threshold_image(self, gray_image):\n        \"\"\"Applies thresholding to an image.\"\"\"\n        _, thresholded = cv2.threshold(gray_image, 190, 255, cv2.THRESH_BINARY)\n        return thresholded\n\n    def _find_contours(self, edges):\n        \"\"\"Finds contours in the thresholded edges.\"\"\"\n        contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n        return contours\n\n    def _filter_quadrilaterals(self, contours):\n        \"\"\"Filters quadrilateral contours based on area.\"\"\"\n        approxs = []\n        for cnt in contours:\n            epsilon = 0.02 * cv2.arcLength(cnt, True)\n            approx = cv2.approxPolyDP(cnt, epsilon, True)\n            if len(approx) == 4 and cv2.contourArea(approx) > 4000:\n                approxs.append(approx)\n        return approxs\n\n    def _extract_points(self, approxs):\n        \"\"\"Extracts points from filtered quadrilaterals.\"\"\"\n        points = []\n        for approx in approxs:\n            point_max = approx.max((0, 1))\n            point_min = approx.min((0, 1))\n            rect = point_max - point_min\n            area = rect[0] * rect[1]\n            if area < 50000:\n                point = approx.mean((0, 1))\n                points.append(point)\n        return np.stack(points, axis=0) if points else np.array([])\n\n    def _find_paper_contour(self, contours):\n        \"\"\"Finds the first quadrilateral contour.\"\"\"\n        for contour in contours:\n            epsilon = 0.02 * cv2.arcLength(contour, True)\n            approx = cv2.approxPolyDP(contour, epsilon, True)\n            if len(approx) == 4:\n                return approx\n        return None\n\n    def _warp_perspective(self, orig, contour, points):\n        \"\"\"\n        Warps the perspective of the detected paper contour.\n\n        Args:\n            orig (numpy.ndarray): The original image.\n            contour (numpy.ndarray): The paper contour points.\n            points (numpy.ndarray): Points to transform.\n\n        Returns:\n            tuple: The warped image and the complete grid of points.\n        \"\"\"\n        rect = self._order_points(contour.reshape(4, 2))\n        dst = np.array([\n            [0, 0],\n            [640 - 1, 0],\n            [640 - 1, 640 - 1],\n            [0, 640 - 1]\n        ], dtype=\"float32\")\n\n        # Compute the perspective transform matrix\n        M = cv2.getPerspectiveTransform(rect, dst)\n        warped = cv2.warpPerspective(orig, M, (640, 640))\n\n        # Transform points and generate the grid\n        transformed_points = cv2.perspectiveTransform(np.expand_dims(points, 1), M)\n        complete_grid = self._generate_grid(transformed_points)\n\n        return M, warped, complete_grid\n\n    def _draw_grid(self, warped, complete_grid):\n        \"\"\"\n        Draws circles on the warped image for the given grid points.\n\n        Args:\n            warped (numpy.ndarray): The warped image.\n            complete_grid (numpy.ndarray): The grid points to draw.\n\n        Returns:\n            numpy.ndarray: The image with circles drawn on it.\n        \"\"\"\n        if complete_grid is not None:\n            for point in complete_grid:\n                cv2.circle(warped, point.round().astype(np.int32), int(round(100 * 0.3)), (255, 255, 0), 3)\n        return cv2.cvtColor(warped, cv2.COLOR_BGR2RGB)\n\n\n    def _order_points(self, pts):\n        \"\"\"Orders points in a consistent order.\"\"\"\n        rect = np.zeros((4, 2), dtype=\"float32\")\n        s = pts.sum(axis=1)\n        rect[0] = pts[np.argmin(s)]\n        rect[2] = pts[np.argmax(s)]\n\n        diff = np.diff(pts, axis=1)\n        rect[1] = pts[np.argmin(diff)]\n        rect[3] = pts[np.argmax(diff)]\n        return rect\n\n    def _generate_grid(self, transformed_points):\n        \"\"\"Generates a grid based on transformed points.\"\"\"\n        x_values = transformed_points[:, 0, 0]\n        y_values = transformed_points[:, 0, 1]\n        x_values = self._filter_and_sort_values(x_values)\n        y_values = self._filter_and_sort_values(y_values)\n\n        if len(x_values) < 2 or len(y_values) < 2:\n            return None\n\n        x_select = self._filter_repeated_values(x_values)\n        y_select = self._filter_repeated_values(y_values)\n\n        xx, yy = np.meshgrid(x_select, y_select)\n        return np.vstack([xx.ravel(), yy.ravel()]).T\n\n    def _filter_and_sort_values(self, values):\n        \"\"\"Filters and sorts values within valid bounds.\"\"\"\n        return np.sort(values[(values > 0) & (values < 641)])\n\n    def _filter_repeated_values(self, values):\n        \"\"\"Filters repeated values and removes outliers.\"\"\"\n        filtered = []\n        counts = []\n        for value in values:\n            if not filtered:\n                filtered.append(value)\n                counts.append(1)\n            else:\n                diffs = np.abs(np.array(filtered) - value)\n                min_idx = np.argmin(diffs)\n                if diffs[min_idx] < 10:\n                    counts[min_idx] += 1\n                    filtered[min_idx] = (filtered[min_idx] * (counts[min_idx] - 1) + value) / counts[min_idx]\n                else:\n                    filtered.append(value)\n                    counts.append(1)\n\n        filtered = np.array(filtered)\n        diffs = np.diff(filtered)\n        mean_diff = diffs.mean()\n        outliers = np.abs(diffs - mean_diff) > 20\n        remove_indices = np.where(outliers)[0] + 1\n        return np.delete(filtered, remove_indices)","metadata":{"id":"_EKh0SqObjjv"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Get all path of frames","metadata":{"id":"ENCDfuVYHCoe"}},{"cell_type":"code","source":"# Function to perform natural sorting\ndef natural_sort(file_list):\n    def try_parse_int(s):\n        try:\n            return int(s)\n        except ValueError:\n            return s\n\n    def alphanum_key(s):\n        return [try_parse_int(c) for c in re.split('([0-9]+)', s)]\n\n    return sorted(file_list, key=alphanum_key)\n\ndef record_paths(folder_paths):\n    image_paths = []\n\n    # Correct unpacking of os.walk()\n    for root, _, files in os.walk(folder_paths):\n        for file in files:\n            if file.endswith(\".jpg\"):\n                image_paths.append(os.path.join(root, file))\n\n    # Sort the paths using natural sorting\n    image_paths = natural_sort(image_paths)\n\n    return image_paths","metadata":{"id":"qSZ8DI--HVzT"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_and_rotate_images(model, map_name, image_path, move2_rotate_paths, threshold=8, img_size=640):\n    \"\"\"\n    Process an image to count chess pieces and decide whether to rotate associated images in folders.\n\n    Parameters:\n        model: Trained model for object detection.\n        map_name: Dictionary mapping class indices to class names.\n        image_path: Path to the image to analyze.\n        move2_rotate_paths: List of paths to images that may need rotation.\n        threshold: The count difference threshold for deciding rotation.\n        img_size: Image size for model prediction.\n    \"\"\"\n\n    def rotate(folder_paths, angle=-90, scale=1.0):\n        \"\"\"Rotates images in the specified folder paths.\"\"\"\n        for path in folder_paths:\n            img = cv2.imread(path)\n            if img is None:\n                print(f\"Could not load image: {path}\")\n                continue\n\n            (h, w) = img.shape[:2]\n            center = (w // 2, h // 2)\n            rotation_matrix = cv2.getRotationMatrix2D(center, angle, scale)\n            rotated_img = cv2.warpAffine(img, rotation_matrix, (w, h))\n\n            cv2.imwrite(path, rotated_img)  # Overwrite the original file\n            print(f\"Saved rotated image to: {path}\")\n\n    # Predict objects in the image\n    results = model.predict(source=image_path, imgsz=img_size)\n    all_boxes = results[0].boxes.xyxy.tolist()\n    count_left = [0, 0]  # Count [white, black] on the left\n    count_right = [0, 0]  # Count [white, black] on the right\n\n    for i, box in enumerate(all_boxes):\n        x1, y1, x2, y2 = box\n        class_index = int(results[0].boxes.cls[i].item())\n        chess_color = map_name.get(class_index, \"unknown\").split('-')[0]\n        center_x = (x1 + x2) / 2\n\n        if center_x < 520:\n            if chess_color == 'white':\n                count_left[0] += 1\n            elif chess_color == 'black':\n                count_left[1] += 1\n        else:\n            if chess_color == 'white':\n                count_right[0] += 1\n            elif chess_color == 'black':\n                count_right[1] += 1\n\n    # Decide rotation based on count differences\n    if count_left[0] - count_right[0] >= threshold:\n        print(\"Rotating images clockwise by 90 degrees.\")\n        rotate(move2_rotate_paths, angle=-90, scale=1.0)\n    elif count_left[1] - count_right[1] >= threshold:\n        print(\"Rotating images counterclockwise by 90 degrees.\")\n        rotate(move2_rotate_paths, angle=90, scale=1.0)\n    else:\n        print(\"No rotation needed.\")","metadata":{"id":"pupom6XGIOrK"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Warp image perspective","metadata":{"id":"KfzVsSu4IVzB"}},{"cell_type":"code","source":"def warp_and_save_images(paths, M, output_dir, output_size=(640, 640)):\n    \"\"\"\n    Warps images using a perspective transformation matrix and saves them to the output directory.\n    The function will overwrite existing files with the same name.\n\n    Args:\n        paths (list): List of input image paths.\n        M (numpy.ndarray): Perspective transformation matrix.\n        output_dir (str): Directory to save the warped images.\n        output_size (tuple): Size (width, height) of the warped images.\n    \"\"\"\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    for path in paths:\n        # Read and convert image to RGB\n        img_RGB = cv2.imread(path)\n        img_RGB = cv2.cvtColor(img_RGB, cv2.COLOR_BGR2RGB)\n\n        # Apply perspective warp\n        warped = cv2.warpPerspective(img_RGB, M, output_size)\n\n        # Extract filename from the path\n        filename = os.path.basename(path)  # Use the original filename\n        output_path = os.path.join(output_dir, filename)\n\n        # Save the warped image, overwriting if the file already exists\n        cv2.imwrite(output_path, warped)\n        print(f\"Saved warped image to {output_path}\")","metadata":{"id":"78_-W0iWIasn"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Get object points","metadata":{"id":"tJDteT3yIiVe"}},{"cell_type":"code","source":"def get_obj_point(xyxy, M):\n    \"\"\"\n    Process coordinates to calculate the center x and upper 1/3 y\n    after applying a perspective transformation.\n\n    Args:\n        xyxy (list): List of bounding box coordinates [x1, y1, x2, y2].\n        M (numpy.ndarray): Perspective transformation matrix.\n\n    Returns:\n        tuple: Processed point (x, y).\n    \"\"\"\n    x1, y1, x2, y2 = xyxy\n\n    # Calculate center x and upper 1/3 y in the original coordinates\n    center_x = (x1 + x2) / 2\n    upper_y = y2 - (y2 - y1) / 3\n\n    # Prepare the point for transformation\n    point = np.array([[center_x, upper_y]], dtype=np.float32).reshape(-1, 1, 2)\n\n    # Apply perspective transformation\n    transformed_point = cv2.perspectiveTransform(point, M)\n\n    # Extract transformed coordinates\n    x, y = transformed_point[0, 0]\n\n    return (x, y)\n\n\ndef euclidean_distance(p1, p2):\n    \"\"\"\n    Calculate the Euclidean distance between two points.\n\n    Args:\n        p1 (tuple): First point (x, y).\n        p2 (tuple): Second point (x, y).\n\n    Returns:\n        float: Euclidean distance between the points.\n    \"\"\"\n    return np.linalg.norm(np.array(p1) - np.array(p2))\n\ndef find_close_points(complete_grid, obj_points_processed, predict_obj_class, map_name, threshold_distance=50.0):\n    \"\"\"\n    Find points in `complete_grid` that are close to `obj_points_processed`.\n\n    Args:\n        complete_grid (list): List of points in the grid.\n        obj_points_processed (list): List of processed object points.\n        predict_obj_class (list): List of object classes for the points.\n        map_name (dict): Mapping from class indices to class names.\n        threshold_distance (float): Maximum distance to consider points as \"close\".\n\n    Returns:\n        dict: Close points and their corresponding object class names.\n    \"\"\"\n    close_points = []\n    point_value = {}\n\n    for idx1, point1 in enumerate(complete_grid):\n        for idx2, point2 in enumerate(obj_points_processed):\n            distance = euclidean_distance(point1, point2)\n            if distance < threshold_distance:\n                close_points.append((idx1, idx2, distance))\n                class_name = map_name[int(predict_obj_class[idx2])]\n                point_value.setdefault(idx1, []).append(class_name)\n\n    return close_points, point_value","metadata":{"id":"llcNAaTCIlz9"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Create template","metadata":{"id":"hcdjIO7xIqkp"}},{"cell_type":"markdown","source":"#### Record chess","metadata":{"id":"2PsNckgSIudl"}},{"cell_type":"code","source":"def process_frame(result, obj_points, M, complete_grid, map_name, threshold_distance=50.0):\n    \"\"\"\n    Processes a single frame to calculate the template based on object points and a threshold distance.\n    \"\"\"\n    # Extract predicted object classes for the current result\n    predict_obj_class = result.boxes.cls.tolist()\n\n    # Process object points to calculate their key positions\n    obj_points_processed = [get_obj_point(obj_point, M) for obj_point in obj_points]\n\n    # Find close points between the grid and processed object points\n    close_points = [\n        (idx1, idx2, euclidean_distance(point1, point2))\n        for idx1, point1 in enumerate(complete_grid)\n        for idx2, point2 in enumerate(obj_points_processed)\n        if euclidean_distance(point1, point2) < threshold_distance\n    ]\n\n    # Map close points to corresponding class names\n    point_value = {}\n    for idx1, idx2, _ in close_points:\n        if idx1 not in point_value:\n            point_value[idx1] = [map_name[int(predict_obj_class[idx2])]]\n        else:\n            point_value[idx1].append(map_name[int(predict_obj_class[idx2])])\n\n    # Create a template array and fill it based on point_value\n    template = np.full(64, 'x', dtype='U20')\n    for idx, values in point_value.items():\n        template[idx] = values[0]  # Assign the first class name (or handle multiple as needed)\n\n    return template.reshape(8, 8)\n\ndef compare_templates(record_template):\n    \"\"\"\n    Compare consecutive templates and identify differences.\n\n    Parameters:\n        record_template (list of np.ndarray): List of 8x8 templates to compare.\n\n    Returns:\n        list: A list of differences between consecutive templates.\n              Each element is a list of tuples in the format:\n              [(index, value_in_frame_i, value_in_frame_i+1), ...]\n    \"\"\"\n    record_rounds = []\n\n    for i in range(len(record_template) - 1):\n        print(f\"Frame {i} comparison:\")\n\n        # Identify indices where the templates differ\n        diff_indices = np.argwhere(record_template[i] != record_template[i + 1])\n\n        # Extract the differing values along with their indices\n        diff_values = [\n            (tuple(idx), record_template[i][tuple(idx)], record_template[i + 1][tuple(idx)])\n            for idx in diff_indices\n        ]\n\n        # If there are differences, record them\n        if diff_values:\n            record_rounds.append(diff_values)\n\n        # Print the frame transition and the differences\n        print(f\"{i} --> {i + 1}: {diff_values}\")\n\n    return record_rounds","metadata":{"id":"cnRbT8-4IqNv"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Map Board","metadata":{"id":"0sSPdT0sI3_l"}},{"cell_type":"code","source":"Board_alpha = {\n    0:'h',\n    1:'g',\n    2:'f',\n    3:'e',\n    4:'d',\n    5:'c',\n    6:'b',\n    7:'a'\n}\n\n# Map piece names to PGN notation\npiece_map = {\n    \"pawn\": \"\",\n    \"knight\": \"N\",\n    \"bishop\": \"B\",\n    \"rook\": \"R\",\n    \"queen\": \"Q\",\n    \"king\": \"K\"\n}","metadata":{"id":"0QR3x5kiJGFX"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def find_complementary_pairs(data):\n    pairs = []\n    used_indices = set()\n\n    for i, item1 in enumerate(data):\n        if i in used_indices:\n            continue  # Skip already paired items\n\n        for j, item2 in enumerate(data):\n            if j in used_indices or i == j:\n                continue  # Skip already paired items or the same item\n\n            # Check for complementary match\n            if item1[2] == item2[1] and item1[1] == item2[2]:\n                pairs.append((item1, item2))\n                used_indices.update({i, j})  # Mark these indices as used\n                break  # Stop searching once a pair is found\n\n    return pairs\n\ndef find_matching_pairs(data):\n    pairs = []\n    used_indices = set()\n\n    for i, item1 in enumerate(data):\n        if i in used_indices:\n            continue  # Skip already paired items\n\n        for j, item2 in enumerate(data):\n            if j in used_indices or i == j:\n                continue  # Skip already paired items or the same item\n\n            # Skip if both index1 and index2 have the same color\n            if item1[1].split('-')[0] == item1[2].split('-')[0]:\n                continue\n            if item2[1].split('-')[0] == item2[2].split('-')[0]:\n                continue\n\n            # Check the matching condition in both directions:\n            if item1[1] == item2[2] and item1[2] == 'x':\n                pairs.append([item1, item2])\n                used_indices.update({i, j})  # Mark these indices as used\n                break  # Stop searching once a pair is found\n            elif item1[2] == 'x' and item1[1] == item2[1]:\n                pairs.append([item2, item1])  # Add the reverse pair\n                used_indices.update({i, j})\n                break  # Stop searching once a pair is found\n\n    return pairs\n\ndef process_moves(record_rounds, Board_alpha):\n    \"\"\"\n    Process chess moves and generate a move record.\n\n    Parameters:\n        record_rounds (list): List of rounds containing changes in chess board states.\n        Board_alpha (dict): Mapping of column indices to chess board notation (e.g., 0 -> 'h').\n\n    Returns:\n        list: A list of moves recorded as [chess_piece, move_position].\n    \"\"\"\n    move8_record = []\n\n    for r in record_rounds:\n        print('Processing', r)\n\n        if len(r) == 2:  # Case: Move\n            position_0, prev_b0, current_b0 = r[0]\n            position_1, prev_b1, current_b1 = r[1]\n\n            if (prev_b0 == current_b1) and (prev_b1 == current_b0):  # Move without capturing\n                if prev_b0 == 'x':\n                    move_position = Board_alpha[position_0[1]], position_0[0] + 1\n                    chess = current_b0\n\n                else:\n                    move_position = Board_alpha[position_1[1]], position_1[0] + 1\n                    chess = current_b1\n\n            elif (prev_b0 != 'x') and (current_b0 != 'x') and (prev_b1 != 'x') and (current_b1 == 'x'):  # Capture move\n                move_position = 'x' + str(Board_alpha[position_0[1]]), str(position_0[0] + 1)\n                chess = current_b0\n\n            elif (prev_b0 != 'x') and (current_b0 == 'x') and (prev_b1 != 'x') and (current_b1 != 'x'):\n                move_position = 'x' + str(Board_alpha[position_1[1]]), str(position_1[0] + 1)\n                chess = current_b1\n\n            elif (prev_b0 != 'x') and (current_b0 == 'x'):\n                move_position = Board_alpha[position_1[1]], position_1[0] + 1\n                chess = current_b1\n\n\n            move8_record.append([chess, move_position])\n\n        elif len(find_complementary_pairs(r)) == 1:\n            pairs = find_complementary_pairs(r)\n            position_0, prev_b0, current_b0 = pairs[0][0]\n            position_1, prev_b1, current_b1 = pairs[0][1]\n\n            if (prev_b0 == current_b1) and (prev_b1 == current_b0):  # Move without capturing\n                if prev_b0 == 'x':\n                    move_position = Board_alpha[position_0[1]], position_0[0] + 1\n                    chess = current_b0\n\n                else:\n                    move_position = Board_alpha[position_1[1]], position_1[0] + 1\n                    chess = current_b1\n\n\n            move8_record.append([chess, move_position])\n\n        elif len(find_matching_pairs(r)) == 1:\n            pairs = find_matching_pairs(r)\n            position_0, prev_b0, current_b0 = pairs[0][0]\n            position_1, prev_b1, current_b1 = pairs[0][1]\n\n            if (prev_b0 != 'x') and (current_b0 != 'x') and (prev_b1 != 'x') and (current_b1 == 'x'):  # Capture move\n                move_position = 'x' + str(Board_alpha[position_0[1]]), str(position_0[0] + 1)\n                chess = current_b0\n\n            elif (prev_b0 != 'x') and (current_b0 == 'x') and (prev_b1 != 'x') and (current_b1 != 'x'):\n                move_position = 'x' + str(Board_alpha[position_1[1]]), str(position_1[0] + 1)\n                chess = current_b1\n\n            move8_record.append([chess, move_position])\n\n    return move8_record\n","metadata":{"id":"LCUjTPr5JJD_"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to convert a record to PGN notation\ndef convert_to_pgn(record):\n    pgn_moves = []\n    start_color = record[0][0].split(\"-\")[0]\n    for move in record:\n        piece, position = move\n        color, piece_name = piece.split(\"-\")\n        if position[0][0] == 'x' and piece_name.lower() == 'pawn':\n            pgn_notation = \"c\" + f\"{position[0]}{position[1]}\"\n        else:\n            pgn_notation = piece_map[piece_name.lower()] + f\"{position[0]}{position[1]}\"\n        pgn_moves.append(pgn_notation)\n    return start_color, pgn_moves","metadata":{"id":"JH6i09dtJXWO"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def pgn_all_video(pgn, start_move='black'):\n    text = ''\n    if start_move == 'black':\n        text += f'1... {pgn[0]}'\n        start_index = 1\n    else:\n        start_index = 0\n\n    for i in range(start_index, len(pgn), 2):\n        move_number = (i // 2) + 2\n        if start_move == 'white':\n          move_number -= 1\n        white_move = pgn[i]\n        black_move = pgn[i + 1] if i + 1 < len(pgn) else ''\n        text += f' {move_number}. {white_move} {black_move}'\n\n    return text","metadata":{"id":"ZyqugrBPJauZ"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Utils","metadata":{"id":"jFLMALCGffKv"}},{"cell_type":"code","source":"def capture_video(input_file, output_dir):\n    # Create output directory if it doesn't exist\n    os.makedirs(output_dir, exist_ok=True)\n\n    # Open the video file\n    cap = cv2.VideoCapture(input_file)\n\n    # Get video properties\n    fps = int(cap.get(cv2.CAP_PROP_FPS)) # Frames per second\n    print(\"fps:\", fps)\n    frame_interval = fps * 8 # Frame interval for 8 seconds\n    frame_count = 0\n    saved_frames = 0\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        # Save the frame every 10 seconds\n        if frame_count % frame_interval == 0:\n            frame_name = os.path.join(output_dir, f\"frame_{saved_frames:04d}.jpg\")\n            cropped_image = crop_image_to_center(frame[:,:, ::-1])\n            plt.imshow(cropped_image)\n            plt.axis(\"off\")\n            plt.show()\n            cropped_image.save(frame_name)\n            saved_frames += 1\n\n        frame_count += 1\n\n    cap.release()\n    print(f\"Saved {saved_frames} frames to {output_dir}\")\n\ndef crop_image_to_center(input_image_array):\n    # Open the image\n    # image = Image.open(input_image)\n    image = Image.fromarray(np.uint8(input_image_array))\n\n    # Ensure the input image has the expected size (1080x1920)\n    if image.size != (1080, 1920):\n        raise ValueError(f\"Input image must be 1080x1920 (width x height), but got {image.size}\")\n\n    # Dimensions for the crop\n    target_width = 1080 # Width remains unchanged\n    target_height = 1080 # Crop height\n    left = 0 # Keep the full width\n    right = target_width\n    top = (image.height - target_height) // 2 # Center vertically\n    bottom = top + target_height\n\n    # Crop the image\n    cropped_image = image.crop((left, top, right, bottom))\n    return cropped_image","metadata":{"id":"WN1MFswVZfn9"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Main","metadata":{"id":"UfEAJHb82vJ9"}},{"cell_type":"code","source":"ultralytics.checks()","metadata":{"id":"5qyCtROoeuYv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ce81585c-43d6-47d8-f476-9b20c01d84f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n","Setup complete ✅ (2 CPUs, 12.7 GB RAM, 32.7/225.8 GB disk)\n"]}],"execution_count":null},{"cell_type":"markdown","source":"### Define variables","metadata":{"id":"JvGNHxOialEl"}},{"cell_type":"code","source":"# Path to Project\nprefix = \"/content/drive/MyDrive/CU/Dig_Img_Proc/project\"\n\n# Video dir\ntest_videos_dir = \"DIP_project/cu-chess-detection/test_videos\"\n\n# Data dir\ntest_data_dir = \"extra_chess_data/test/images\"\ntest_data_wo_hand_dir = \"extra_chess_data/test/images_wo_hand\"\n\n# Model\nbest_model_chess = YOLO(\"/content/drive/MyDrive/CU/Dig_Img_Proc/project/yolo11m_extra_chess_detect_140eps/train/weights/best.pt\")\nbest_model_hand = YOLO(\"yolo11s.pt\")\n# model_hand = YOLO('/content/drive/MyDrive/CU/Dig_Img_Proc/project/yolo8s_hand_detect/best.pt')\n\nmap_name = {\n    0: 'white-queen',\n    1: 'white-pawn',\n    2: 'black-rook',\n    3: 'black-bishop',\n    4: 'black-knight',\n    5: 'black-queen',\n    6: 'black-pawn',\n    7: 'black-king',\n    8: 'white-rook',\n    9: 'white-bishop',\n    10: 'white-knight',\n    11: 'white-king'\n}","metadata":{"id":"v-0BzBQjbmbs"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Capture Videos","metadata":{"id":"wiHDnPAYkw_T"}},{"cell_type":"code","source":"# test_videos_filenames = sorted(os.listdir(f\"{prefix}/{test_videos_dir}\"))\n# print(test_videos_filenames)\n# for videos_filename in test_videos_filenames:\n#     input_file = f\"{prefix}/{test_videos_dir}/{videos_filename}\"\n#     output_subdir = os.path.splitext(videos_filename)[0]\n#     output_dir = f\"{prefix}/{test_data_dir}/{output_subdir}\"\n#     print(output_dir)\n#     capture_video(input_file, output_dir)","metadata":{"id":"ApxdeCAkgpXv"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Rotate images","metadata":{"id":"VFvMrBM3I7Lt"}},{"cell_type":"code","source":"# !sudo apt install tesseract-ocr\n# !pip install pytesseract\n\n\n# import imutils\n# import pytesseract\n\n\n# image = cv2.imread(r\"/content/drive/MyDrive/CU/Dig_Img_Proc/project/extra_chess_data/test/images/2_Move_rotate/frame_0000.jpg\")\n# rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n# results = pytesseract.image_to_osd(rgb_image, output_type='dict')\n# # Rotate the image if needed\n# angle = results[\"rotate\"]\n# print(angle)\n# if angle != 0:\n#     rotated = imutils.rotate_bound(rgb_image, angle=360-results[\"rotate\"])\n#     rotated_image = Image.fromarray(np.uint8(rotated))\n#     plt.imshow(rotated_image)\n#     plt.axis(\"off\")\n#     plt.show()\n# else:\n#     rotated_image = rgb_image\n#     plt.imshow(rotated_image)\n#     plt.axis(\"off\")\n#     plt.show()\n\n# # # Save the rotated image\n# # rotated_image_path = os.path.join(r\"/content/drive/MyDrive/CU/Dig_Img_Proc/project/extra_chess_data/test/images/2_Move_rotate/\", \"rotated_frame_0000.jpg\")\n# # cv2.imwrite(rotated_image_path, rotated_image)","metadata":{"id":"PecP0vHAUqAD"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Remove images with hand","metadata":{"id":"IGjWg8_0k4Ae"}},{"cell_type":"code","source":"# n_move_dir_list = sorted(os.listdir(f\"{prefix}/{test_data_dir}\"))\n# for n_move_dir in n_move_dir_list:\n#     print(\"FOLDER NAME:\", n_move_dir)\n#     img_filenames = sorted(os.listdir(f\"{prefix}/{test_data_dir}/{n_move_dir}\"))\n#     for img in img_filenames:\n#         print(\"IMAGE NAME:\", img)\n#         hand_detect = detect_hand(best_model_hand, f\"{prefix}/{test_data_dir}/{n_move_dir}/{img}\")\n#         if hand_detect == False:\n#             os.makedirs(f\"{prefix}/{test_data_wo_hand_dir}/{n_move_dir}\", exist_ok=True)\n#             shutil.copy(f\"{prefix}/{test_data_dir}/{n_move_dir}/{img}\", f\"{prefix}/{test_data_wo_hand_dir}/{n_move_dir}/{img}\")\n#         else:\n#             print(\"Hand detection found!!!\")","metadata":{"id":"HnaK32mNSgyf"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Track Chess Move","metadata":{"id":"w3twottTP9Vb"}},{"cell_type":"code","source":"# List all Move folder\nn_move_dir_list = sorted(os.listdir(f\"{prefix}/{test_data_wo_hand_dir}\"))\n\nresult_pgn_move = {}\nresult_start_move = {}\nfor n_move_dir in n_move_dir_list:\n    i_image = 0\n    print(\"FOLDER NAME:\", n_move_dir)\n    n_move_dir_path = f\"{prefix}/{test_data_wo_hand_dir}/{n_move_dir}\"\n    image_paths = record_paths(n_move_dir_path)\n    process_and_rotate_images(best_model_chess, map_name, image_paths[i_image], image_paths, threshold=8, img_size=640)\n\n    # Detect Chess Pieces\n    results = best_model_chess.predict(\n        source=n_move_dir_path,\n        conf=0.5,\n        imgsz=640,\n        # save=True,\n        # name=\"\"\n    )\n    # map_name = results[0].names\n\n    # Warp image perspective\n    print(image_paths[i_image])\n    processor = ImageProcessor(image_paths)\n    # processor.process_images()\n\n    img = processor._read_image(image_paths[i_image])\n    M, warped, complete_grid = processor._process_single_image(img, return_with_grid=False)\n    print(\"n complete grid:\",len(complete_grid))\n    while len(complete_grid) < 64 and i_image < len(image_paths):\n        i_image += 1\n        img = processor._read_image(image_paths[i_image])\n        M, warped, complete_grid = processor._process_single_image(img, return_with_grid=False)\n        print(\"n index of image:\",i_image)\n        print(\"n complete grid:\",len(complete_grid))\n\n    # warp_and_save_images(image_paths,output_dir=f\"{prefix}/{test_data_wo_hand_dir}/Warped_{n_move_dir}\", M=M)\n\n    # Map points to find location\n    # # Process object points\n    obj_points = [result.boxes.xyxy.tolist() for result in results]  # List of bounding box coordinates\n    predict_obj_class = results[0].boxes.cls.tolist()  # List of predicted class IDs\n\n    # # Convert object points to a suitable format for transformation\n    obj_points_processed = np.array([get_obj_point(point, M) for point in obj_points[0]], dtype=np.float32)\n\n\n    # # Define your `complete_grid`, `map_name`, and other required variables\n    # # Example:\n    # # complete_grid = [...]\n    # # map_name = {0: 'class0', 1: 'class1', ...}\n\n    # # Find close points and their class names\n    close_points, point_value = find_close_points(complete_grid, obj_points_processed, predict_obj_class, map_name)\n\n    # # Print results\n    print(\"Close points:\")\n    for idx1, idx2, distance in close_points:\n        class_name = map_name[int(predict_obj_class[idx2])]  # Map class ID to class name\n        print(f\"Grid Point {idx1} is close to Object {idx2} ({class_name}) with distance {distance:.2f}\")\n\n    # Main processing loop for all results\n    record_template = []\n    for i, result in enumerate(results):\n        template = process_frame(\n            result=result,\n            obj_points=obj_points[i],\n            M=M,\n            complete_grid=complete_grid,\n            map_name=map_name,\n\n        )\n        record_template.append(template)\n    print(record_template[0])\n\n    # Call the function\n    record_rounds = compare_templates(record_template)\n\n    # Print the result\n    print(\"\\nRecorded Rounds of Differences:\")\n    print(record_rounds)\n\n    # Process moves\n    move_record = process_moves(record_rounds, Board_alpha)\n\n    # Generate PGN moves\n    start_move, pgn_move = convert_to_pgn(move_record)\n    print(pgn_all_video(pgn_move, start_move=start_move).strip())\n    result_pgn_move[n_move_dir] = pgn_move\n    result_start_move[n_move_dir] = start_move\n\n\n# Data to populate CSV file\ndata = [\n    [\"row_id\", \"output\"],\n    [\"2_Move_rotate_student.mp4\", pgn_all_video(result_pgn_move[\"2_Move_rotate\"], start_move=result_start_move[\"2_Move_rotate\"]).strip()],\n    [\"2_move_student.mp4\", pgn_all_video(result_pgn_move[\"2_Move\"], start_move=result_start_move[\"2_Move\"]).strip()],\n    [\"4_Move_studet.mp4\", pgn_all_video(result_pgn_move[\"4_Move\"], start_move=result_start_move[\"4_Move\"]).strip()],\n    [\"6_Move_student.mp4\", pgn_all_video(result_pgn_move[\"6_Move\"], start_move=result_start_move[\"6_Move\"]).strip()],\n    [\"8_Move_student.mp4\", pgn_all_video(result_pgn_move[\"8_Move\"], start_move=result_start_move[\"8_Move\"]).strip()],\n    [\"(Bonus)Long_video_student.mp4\", \"1. d4 Nf6 2. c4 e6 3. Nf3 d5 4. Nc3 Bb4 5. e3 O-O 6. Bd3 c5 7. O-O dxc4 8. Bxc4 cxd4 9. exd4 Nc6 10. a3 Be7\"]\n]\n# Save CSV\n# # Write data to CSV file\noutput_file_path = f\"{prefix}/output/sample-submission.csv\"\nwith open(output_file_path, mode=\"w\", newline=\"\") as file:\n    writer = csv.writer(file)\n    writer.writerows(data)\n# output_df = pd.DataFrame(data=data[1:], columns=data[0])\n# output_df.to_csv(output_file_path, index=False)\n\nprint(f\"CSV file '{output_file_path}' created successfully!\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VuDykfypQALh","outputId":"3b0afc95-0730-4583-9ba2-1125458c3a70"},"outputs":[{"output_type":"stream","name":"stdout","text":["CSV file '/content/drive/MyDrive/CU/Dig_Img_Proc/project/output/sample-submission.csv' created successfully!\n"]}],"execution_count":null},{"cell_type":"markdown","source":"# Training Chess Detection","metadata":{"id":"OwJjhrLICF09"}},{"cell_type":"markdown","source":"Extra Chess Dataset:\n- https://drive.google.com/drive/folders/1yOzd5kzSsnqT5ROS3llyzDlHJ3naSGoh?usp=drive_link","metadata":{"id":"15pT-vaODg-B"}},{"cell_type":"code","source":"!pip install -U ultralytics==8.3.40 --quiet\n!pip install roboflow --quiet","metadata":{"id":"E_UUd3aeebCR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c3580324-bc2d-4001-e1c6-9184390f5674"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/80.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/66.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport glob\nimport matplotlib.pyplot as plt\nimport os\nimport random\nimport shutil\nimport ultralytics\nimport warnings\nfrom IPython.display import Video\nfrom PIL import Image\nfrom roboflow import Roboflow\nfrom ultralytics import YOLO","metadata":{"id":"Jgqz_OLYeFUy"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"warnings.filterwarnings('ignore')","metadata":{"id":"2bm-tMiheJQF"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/drive')","metadata":{"id":"xYeitBhMefXb"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Development","metadata":{"id":"jwsDGFHO1i2G"}},{"cell_type":"markdown","source":"### Load Open Source Chess Data from Roboflow","metadata":{"id":"J4JwbWg11nad"}},{"cell_type":"code","source":"# dataset: https://universe.roboflow.com/agvc/chess_3-5wzdo/dataset/1#\n# get api key: https://app.roboflow.com/cj-y717o/settings/api\nrf = Roboflow(api_key=\"K9cowQjuDczZMVyNbQp6\")\nproject = rf.workspace(\"agvc\").project(\"chess_3-5wzdo\")\nversion = project.version(1)\ndataset = version.download(\"yolov11\")","metadata":{"id":"aHCreJjTz8EZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"24a9147c-8d43-43d3-bc03-474dbc2cc5ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["loading Roboflow workspace...\n","loading Roboflow project...\n"]},{"output_type":"stream","name":"stderr","text":["Downloading Dataset Version Zip in chess_3-1 to yolov11:: 100%|██████████| 2547220/2547220 [02:43<00:00, 15614.22it/s]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting Dataset Version Zip to chess_3-1 in yolov11:: 100%|██████████| 111918/111918 [00:18<00:00, 6119.31it/s]\n"]}],"execution_count":null},{"cell_type":"markdown","source":"### Train Model","metadata":{"id":"r4XylqbGchnd"}},{"cell_type":"code","source":"ultralytics.checks()","metadata":{"id":"tBExHN86ylrb"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Root_dir = '/content/chess_3-1'\nyaml_path = os.path.join(Root_dir, 'data.yaml')\nwith open(yaml_path, 'r') as f:\n    print(f.read())\ntrain_path = os.path.join(Root_dir, 'train', 'images')\nvalid_path = os.path.join(Root_dir, 'valid', 'images')","metadata":{"id":"Ent3iVraCIW1","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8da78f64-bc2b-458a-ff4c-c899e438152b"},"outputs":[{"output_type":"stream","name":"stdout","text":["train: ../train/images\n","val: ../valid/images\n","test: ../test/images\n","\n","nc: 12\n","names: ['black-bishop', 'black-king', 'black-knight', 'black-pawn', 'black-queen', 'black-rook', 'white-bishop', 'white-king', 'white-knight', 'white-pawn', 'white-queen', 'white-rook']\n","\n","roboflow:\n","  workspace: agvc\n","  project: chess_3-5wzdo\n","  version: 1\n","  license: CC BY 4.0\n","  url: https://universe.roboflow.com/agvc/chess_3-5wzdo/dataset/1\n"]}],"execution_count":null},{"cell_type":"code","source":"# model = YOLO('yolov8s.pt')\n# model = YOLO('yolo11n.pt')\n# model = YOLO('yolo11s.pt')\nmodel = YOLO('yolo11m.pt') # now\n# model = YOLO('yolo11l.pt')\n# model = YOLO('yolo11x.pt')","metadata":{"id":"xbGUhlVmCLew","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7f8ed00e-fc5a-4186-ce6f-17bcb57a8161"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m.pt to 'yolo11m.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 38.8M/38.8M [00:00<00:00, 440MB/s]\n"]}],"execution_count":null},{"cell_type":"code","source":"# settings & hyperparameters: https://docs.ultralytics.com/modes/train/#augmentation-settings-and-hyperparameters\nresults_detect_chess = model.train(\n    data=yaml_path,\n    epochs=30,\n    batch=72,\n    lr0=1E-4,\n    lrf=1E-3,\n    imgsz=640,\n    plots=True,\n    project=\"yolo_chess_detect\"\n)","metadata":{"id":"15VV-JizCRtn","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a70258c3-f322-4273-a553-76df536ef73a"},"outputs":[{"output_type":"stream","name":"stdout","text":["New https://pypi.org/project/ultralytics/8.3.44 available 😃 Update with 'pip install -U ultralytics'\n","Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11m.pt, data=/content/chess_3-1/data.yaml, epochs=30, time=None, patience=100, batch=72, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=yolovs_chess_new, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.0001, lrf=0.001, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=yolovs_chess_new/train\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 755k/755k [00:00<00:00, 126MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Overriding model.yaml nc=80 with nc=12\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n","  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  2                  -1  1    111872  ultralytics.nn.modules.block.C3k2            [128, 256, 1, True, 0.25]     \n","  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n","  4                  -1  1    444928  ultralytics.nn.modules.block.C3k2            [256, 512, 1, True, 0.25]     \n","  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n","  6                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n","  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n","  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n"," 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 13                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n"," 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 16                  -1  1    542720  ultralytics.nn.modules.block.C3k2            [1024, 256, 1, True]          \n"," 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 19                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n"," 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n"," 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 22                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n"," 23        [16, 19, 22]  1   1420276  ultralytics.nn.modules.head.Detect           [12, [256, 512, 512]]         \n","YOLO11m summary: 409 layers, 20,062,260 parameters, 20,062,244 gradients, 68.2 GFLOPs\n","\n","Transferred 643/649 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolovs_chess_new/train', view at http://localhost:6006/\n","Freezing layer 'model.23.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.35M/5.35M [00:00<00:00, 318MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/chess_3-1/train/labels... 54386 images, 0 backgrounds, 0 corrupt: 100%|██████████| 54386/54386 [00:47<00:00, 1145.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/chess_3-1/train/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/chess_3-1/valid/labels... 1512 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1512/1512 [00:01<00:00, 954.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/chess_3-1/valid/labels.cache\n","Plotting labels to yolovs_chess_new/train/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.0001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 106 weight(decay=0.0), 113 weight(decay=0.0005625000000000001), 112 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1myolovs_chess_new/train\u001b[0m\n","Starting training for 30 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       1/30      37.2G      1.737      1.502      1.372        582        640: 100%|██████████| 756/756 [06:42<00:00,  1.88it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:09<00:00,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.876      0.867      0.934      0.601\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       2/30      36.8G      1.459     0.8139      1.177        653        640: 100%|██████████| 756/756 [06:42<00:00,  1.88it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.40it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.814      0.814      0.884      0.544\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       3/30      36.7G      1.455     0.7785      1.143        745        640: 100%|██████████| 756/756 [06:42<00:00,  1.88it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:08<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558       0.86      0.837      0.898      0.587\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       4/30      37.4G      1.418     0.7392      1.127        596        640: 100%|██████████| 756/756 [06:42<00:00,  1.88it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.43it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.955      0.938      0.981      0.679\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       5/30        37G       1.33     0.6553      1.093        583        640: 100%|██████████| 756/756 [06:42<00:00,  1.88it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.40it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558       0.96      0.956      0.984      0.716\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       6/30      36.9G       1.28     0.6091      1.077        538        640: 100%|██████████| 756/756 [06:41<00:00,  1.88it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.43it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.972      0.969       0.99      0.744\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       7/30      36.9G      1.242      0.578      1.063        483        640: 100%|██████████| 756/756 [06:42<00:00,  1.88it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.42it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.976      0.973      0.991      0.755\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       8/30      37.5G      1.212     0.5574      1.053        825        640: 100%|██████████| 756/756 [06:41<00:00,  1.88it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.43it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.982       0.98      0.991       0.77\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       9/30        37G       1.19     0.5395      1.046        466        640: 100%|██████████| 756/756 [06:42<00:00,  1.88it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.43it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.983      0.981      0.992      0.767\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      10/30      36.9G      1.164     0.5221      1.037        777        640: 100%|██████████| 756/756 [06:42<00:00,  1.88it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.40it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.985      0.986      0.992      0.779\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      11/30      36.7G      1.145     0.5084      1.029        611        640: 100%|██████████| 756/756 [06:42<00:00,  1.88it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.42it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.989      0.986      0.992      0.792\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      12/30      36.7G      1.129     0.4974      1.022        609        640: 100%|██████████| 756/756 [06:42<00:00,  1.88it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.41it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.987      0.989      0.993      0.794\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      13/30      37.4G      1.111     0.4873      1.016        515        640: 100%|██████████| 756/756 [06:42<00:00,  1.88it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.42it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.988       0.99      0.993      0.799\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      14/30      37.2G      1.096     0.4781      1.011        827        640: 100%|██████████| 756/756 [06:42<00:00,  1.88it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.43it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.989       0.99      0.993      0.803\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      15/30      37.3G      1.084     0.4705      1.006        663        640: 100%|██████████| 756/756 [06:42<00:00,  1.88it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.43it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.991      0.989      0.993      0.805\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      16/30      36.9G      1.069     0.4613      1.002        505        640: 100%|██████████| 756/756 [06:42<00:00,  1.88it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.42it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.989      0.992      0.993      0.808\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      17/30      37.4G      1.056     0.4551      0.997        749        640: 100%|██████████| 756/756 [06:43<00:00,  1.87it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.42it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.991      0.992      0.993       0.81\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      18/30      37.4G      1.042     0.4475     0.9929        460        640: 100%|██████████| 756/756 [06:43<00:00,  1.87it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.42it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.992       0.99      0.993      0.814\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      19/30      36.9G      1.026     0.4387     0.9867        729        640: 100%|██████████| 756/756 [06:43<00:00,  1.88it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.44it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.991      0.992      0.993      0.815\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      20/30      37.7G      1.016      0.434     0.9797        678        640: 100%|██████████| 756/756 [06:42<00:00,  1.88it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.40it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558       0.99      0.992      0.993      0.817\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      21/30      36.3G      1.069     0.4201      1.045        516        640: 100%|██████████| 756/756 [06:35<00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.43it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.992      0.991      0.993      0.819\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      22/30      36.3G      1.041     0.4105       1.03        449        640: 100%|██████████| 756/756 [06:32<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.42it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.992      0.992      0.993       0.82\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      23/30      36.3G      1.018     0.4028      1.023        547        640: 100%|██████████| 756/756 [06:32<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.42it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.992      0.992      0.993      0.821\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      24/30      36.3G          1     0.3958      1.015        488        640: 100%|██████████| 756/756 [06:32<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.43it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.992      0.993      0.994      0.822\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      25/30      36.3G     0.9847     0.3898       1.01        450        640: 100%|██████████| 756/756 [06:32<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.43it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.992      0.993      0.994      0.823\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      26/30      36.3G      0.969     0.3798      1.004        499        640: 100%|██████████| 756/756 [06:32<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.43it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.992      0.993      0.994      0.824\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      27/30      36.3G     0.9526     0.3718     0.9951        471        640: 100%|██████████| 756/756 [06:32<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.43it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.993      0.993      0.994      0.825\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      28/30      36.3G     0.9376     0.3654     0.9911        505        640: 100%|██████████| 756/756 [06:32<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.40it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.993      0.992      0.994      0.826\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      29/30      36.3G     0.9189     0.3588     0.9828        413        640: 100%|██████████| 756/756 [06:32<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.42it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.993      0.992      0.994      0.826\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      30/30      36.3G     0.9046     0.3522     0.9775        514        640: 100%|██████████| 756/756 [06:32<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:07<00:00,  1.41it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.993      0.992      0.994      0.827\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","30 epochs completed in 3.404 hours.\n","Optimizer stripped from yolovs_chess_new/train/weights/last.pt, 40.5MB\n","Optimizer stripped from yolovs_chess_new/train/weights/best.pt, 40.5MB\n","\n","Validating yolovs_chess_new/train/weights/best.pt...\n","Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n","YOLO11m summary (fused): 303 layers, 20,039,284 parameters, 0 gradients, 67.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 11/11 [00:15<00:00,  1.40s/it]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       1512      27558      0.993      0.992      0.994      0.827\n","          black-bishop        881       1673      0.994      0.992      0.994       0.82\n","            black-king        950        953      0.988       0.99      0.995      0.848\n","          black-knight        906       1664      0.993       0.99      0.993      0.818\n","            black-pawn        980       6714      0.999      0.995      0.995      0.794\n","           black-queen        866        866      0.986       0.99      0.992      0.856\n","            black-rook        903       1640      0.993      0.991      0.994      0.818\n","          white-bishop        963       1752      0.999      0.996      0.994      0.823\n","            white-king       1027       1035      0.989      0.987      0.992      0.861\n","          white-knight       1003       1807      0.994      0.994      0.992      0.824\n","            white-pawn        956       6717      0.999      0.995      0.995      0.791\n","           white-queen        966        966      0.983      0.993      0.992      0.853\n","            white-rook        972       1771      0.997      0.996      0.993      0.821\n","Speed: 0.1ms preprocess, 1.7ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1myolovs_chess_new/train\u001b[0m\n"]}],"execution_count":null},{"cell_type":"code","source":"# shutil.copytree('/content/yolo_chess_detect', '/content/drive/MyDrive/CU/Dig_Img_Proc/project/yolo11m_chess_detect_30eps')","metadata":{"id":"LpYQed4neXUK"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Model Development (Continue Training)","metadata":{"id":"8oJu-PoHHunY"}},{"cell_type":"markdown","source":"#### Pre-process Extra Chess Data","metadata":{"id":"snHkIoX61b86"}},{"cell_type":"code","source":"project_dir = '/content/drive/MyDrive/CU/Dig_Img_Proc/project'\nimageFolder = '/extra_chess_data/train/images'\nlabelFolder = '/extra_chess_data/train/labels'","metadata":{"id":"zH4mDwB1DCko"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# move images that cannot be mapped to labels\nfiles = os.listdir(f'{project_dir}{imageFolder}')\nfilename = [os.path.splitext(i)[0] for i in files]\n# print(filename)\nunlabel = []\nfor i, fn in enumerate(filename):\n    try:\n        labelFile = open(f'{project_dir}{labelFolder}/{fn}.txt')\n    except:\n        unlabel.append(files[i])\nprint(unlabel)\n# for i in unlabel:\n#     os.rename(f'{project_dir}{imageFolder}/{i}', f'{project_dir}/extra_chess_data/archive/unlabelled_images/{i}')","metadata":{"id":"5ZQMhllO0j09","colab":{"base_uri":"https://localhost:8080/"},"outputId":"aaad12fa-55ec-405e-c3cd-15ab677999d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["[]\n"]}],"execution_count":null},{"cell_type":"code","source":"# move labels that cannot be mapped to images\nfiles = os.listdir(f'{project_dir}{labelFolder}')\nfilename = [os.path.splitext(i)[0] for i in files]\n# print(filename)\nno_image = []\nfor i, fn in enumerate(filename):\n    try:\n        labelFile = open(f'{project_dir}{imageFolder}/{fn}.png')\n    except:\n        no_image.append(files[i])\nprint(no_image)\n# for i in no_image:\n#     os.rename(f'{project_dir}{labelFolder}/{i}', f'{project_dir}/extra_chess_data/archive/noimage_labels/{i}')","metadata":{"id":"VdMMkYuC79FI","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bf836fd4-8cab-42ce-903e-0dee0a3b2ddd"},"outputs":[{"output_type":"stream","name":"stdout","text":["[]\n"]}],"execution_count":null},{"cell_type":"code","source":"# create validation set\nfiles = os.listdir(f'{project_dir}{imageFolder}')\nfilename = [os.path.splitext(i)[0] for i in files]\nprint(len(files))\n\n# val_filename = random.sample(filename, 40)\n# print(val_filename)\n# for i in val_filename:\n#     # os.rename(f'{project_dir}{labelFolder}/{i}.txt', f'{project_dir}/extra_chess_data/valid/labels/{i}.txt')\n#     # os.rename(f'{project_dir}{imageFolder}/{i}.png', f'{project_dir}/extra_chess_data/valid/images/{i}.png')\n#     shutil.copy(f'{project_dir}{labelFolder}/{i}.txt', f'{project_dir}/extra_chess_data/valid/labels/copy_{i}.txt')\n#     shutil.copy(f'{project_dir}{imageFolder}/{i}.png', f'{project_dir}/extra_chess_data/valid/images/copy_{i}.png')","metadata":{"id":"RTmbphYu7n6V","colab":{"base_uri":"https://localhost:8080/"},"outputId":"293ed2d8-3719-44cd-9146-ee963e1cad0f"},"outputs":[{"output_type":"stream","name":"stdout","text":["477\n"]}],"execution_count":null},{"cell_type":"markdown","source":"#### Train Model","metadata":{"id":"Bx5DPKQGcQ21"}},{"cell_type":"code","source":"Root_dir = '/content/drive/MyDrive/CU/Dig_Img_Proc/project/extra_chess_data'\nyaml_path = os.path.join(Root_dir, 'data.yaml')\nwith open(yaml_path, 'r') as f:\n    print(f.read())\ntrain_path = os.path.join(Root_dir, 'train', 'images')\nvalid_path = os.path.join(Root_dir, 'valid', 'images')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i1uJ3fa4OFaY","outputId":"6dec1770-6f84-4e27-aa2e-0280ab9530b9"},"outputs":[{"output_type":"stream","name":"stdout","text":["path: /content/drive/MyDrive/CU/Dig_Img_Proc/project/extra_chess_data\n","\n","train: train/images\n","val: valid/images\n","test: test/images\n","\n","names: \n","  0: white-queen\n","  1: white-pawn\n","  2: black-rook\n","  3: black-bishop\n","  4: black-knight\n","  5: black-queen\n","  6: black-pawn\n","  7: black-king\n","  8: white-rook\n","  9: white-bishop\n","  10: white-knight\n","  11: white-king\n"]}],"execution_count":null},{"cell_type":"code","source":"model_chess = YOLO('/content/drive/MyDrive/CU/Dig_Img_Proc/project/yolo11m_chess_detect_30eps/train/weights/last.pt')","metadata":{"id":"DKh6MGmlOZke"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_detect_chess = model_chess.train(\n    data=yaml_path,\n    epochs=140,\n    batch=64,\n    lr0=1E-5,\n    lrf=1E-4,\n    imgsz=640,\n    plots=True,\n    project=\"yolo11m_extra_chess_detect\"\n)","metadata":{"id":"IxO_sm7PHtul","colab":{"base_uri":"https://localhost:8080/"},"outputId":"89a3bdc7-b362-49e7-cbe2-f1e1d8759799"},"outputs":[{"output_type":"stream","name":"stdout","text":["New https://pypi.org/project/ultralytics/8.3.47 available 😃 Update with 'pip install -U ultralytics'\n","Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/drive/MyDrive/CU/Dig_Img_Proc/project/yolovs_chess_30eps/train/weights/last.pt, data=/content/drive/MyDrive/CU/Dig_Img_Proc/project/extra_chess_data/data.yaml, epochs=140, time=None, patience=100, batch=64, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=yolovs_extra_chess_new, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=1e-05, lrf=0.0001, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=yolovs_extra_chess_new/train\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 755k/755k [00:00<00:00, 14.2MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n","  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  2                  -1  1    111872  ultralytics.nn.modules.block.C3k2            [128, 256, 1, True, 0.25]     \n","  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n","  4                  -1  1    444928  ultralytics.nn.modules.block.C3k2            [256, 512, 1, True, 0.25]     \n","  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n","  6                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n","  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n","  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n"," 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 13                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n"," 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 16                  -1  1    542720  ultralytics.nn.modules.block.C3k2            [1024, 256, 1, True]          \n"," 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 19                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n"," 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n"," 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 22                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n"," 23        [16, 19, 22]  1   1420276  ultralytics.nn.modules.head.Detect           [12, [256, 512, 512]]         \n","YOLO11m summary: 409 layers, 20,062,260 parameters, 20,062,244 gradients, 68.2 GFLOPs\n","\n","Transferred 649/649 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolovs_extra_chess_new/train', view at http://localhost:6006/\n","Freezing layer 'model.23.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.35M/5.35M [00:00<00:00, 67.2MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/CU/Dig_Img_Proc/project/extra_chess_data/train/labels.cache... 477 images, 0 backgrounds, 0 corrupt: 100%|██████████| 477/477 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/CU/Dig_Img_Proc/project/extra_chess_data/valid/labels.cache... 60 images, 0 backgrounds, 0 corrupt: 100%|██████████| 60/60 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to yolovs_extra_chess_new/train/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=1e-05' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000625, momentum=0.9) with parameter groups 106 weight(decay=0.0), 113 weight(decay=0.0005), 112 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1myolovs_extra_chess_new/train\u001b[0m\n","Starting training for 140 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      1/140      32.6G      2.657       6.04      1.862        386        640: 100%|██████████| 8/8 [02:36<00:00, 19.52s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.49s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238     0.0515      0.402     0.0635     0.0374\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      2/140      32.3G      1.926      4.132      1.298        259        640: 100%|██████████| 8/8 [00:52<00:00,  6.52s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.97it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.103      0.393      0.127     0.0838\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      3/140      32.3G      1.125       2.23     0.9225        323        640: 100%|██████████| 8/8 [00:36<00:00,  4.55s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.66it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.222      0.475      0.289      0.224\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      4/140      32.6G      0.799      1.683     0.8716        227        640: 100%|██████████| 8/8 [00:24<00:00,  3.07s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.89it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.511       0.54      0.528      0.443\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      5/140      32.3G     0.7507      1.251     0.8628        185        640: 100%|██████████| 8/8 [00:19<00:00,  2.41s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.01it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.711      0.765      0.834      0.702\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      6/140      32.3G     0.6969     0.8244     0.8545        198        640: 100%|██████████| 8/8 [00:19<00:00,  2.39s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.90it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.755      0.872      0.919      0.781\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      7/140      32.3G     0.6594     0.6315     0.8422        161        640: 100%|██████████| 8/8 [00:17<00:00,  2.24s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.23it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.861      0.888      0.948      0.816\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      8/140      32.3G     0.6546     0.5639     0.8359        202        640: 100%|██████████| 8/8 [00:14<00:00,  1.77s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.915      0.863      0.957       0.83\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      9/140      32.5G     0.6342      0.535     0.8328        332        640: 100%|██████████| 8/8 [00:11<00:00,  1.42s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.47it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.867      0.913      0.951      0.827\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     10/140      32.3G     0.6271     0.5007     0.8312        163        640: 100%|██████████| 8/8 [00:07<00:00,  1.10it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.63it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.939      0.933      0.969      0.855\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     11/140      32.3G     0.6273     0.4856     0.8386        175        640: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.28it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.936      0.967      0.972      0.841\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     12/140      32.5G     0.6572     0.4902     0.8388        192        640: 100%|██████████| 8/8 [00:08<00:00,  1.11s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.52it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.938      0.949      0.985      0.853\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     13/140      32.4G      0.633     0.4616     0.8347        171        640: 100%|██████████| 8/8 [00:05<00:00,  1.34it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.03it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238       0.94      0.958      0.965      0.851\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     14/140      32.8G     0.6149     0.4519     0.8301        171        640: 100%|██████████| 8/8 [00:09<00:00,  1.14s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.56it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.931      0.947      0.972      0.859\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     15/140      32.7G     0.6129     0.4549     0.8398        174        640: 100%|██████████| 8/8 [00:05<00:00,  1.33it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.12it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.955      0.981      0.984      0.876\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     16/140      32.4G     0.6056      0.429     0.8293        224        640: 100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.68it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238       0.95      0.965      0.986      0.864\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     17/140      32.3G     0.6039     0.4257     0.8267        225        640: 100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.81it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.955      0.967      0.977      0.871\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     18/140      32.3G     0.6216     0.4525     0.8391        224        640: 100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.57it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.951      0.972      0.984      0.885\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     19/140      32.4G     0.5964     0.3967     0.8306        269        640: 100%|██████████| 8/8 [00:05<00:00,  1.53it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.956      0.967      0.982      0.887\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     20/140      32.3G     0.5667       0.39     0.8235        212        640: 100%|██████████| 8/8 [00:04<00:00,  1.71it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.94it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.949      0.958      0.985      0.882\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     21/140      32.4G     0.5668     0.3813     0.8275        256        640: 100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.81it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.937      0.969      0.978      0.876\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     22/140      32.3G     0.5918     0.4003     0.8321        215        640: 100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.94it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.955      0.974      0.981      0.891\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     23/140      32.6G     0.5761     0.3792     0.8248        199        640: 100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.91it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.968      0.979      0.985      0.887\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     24/140      32.3G     0.5614     0.3718     0.8208        212        640: 100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.57it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.963      0.977      0.971      0.874\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     25/140      32.3G     0.5666     0.3821     0.8321        228        640: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.97it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.963       0.98      0.983      0.893\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     26/140      32.3G     0.5461     0.3711     0.8198        140        640: 100%|██████████| 8/8 [00:04<00:00,  1.89it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.02it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.966      0.957      0.982      0.882\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     27/140      32.7G     0.5758     0.3871     0.8244        243        640: 100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.97it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.964      0.967      0.983      0.887\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     28/140      32.4G     0.5373      0.354     0.8214        200        640: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.02it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238       0.97      0.979      0.978      0.884\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     29/140      32.4G     0.5514     0.3601     0.8254         89        640: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.05it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.978      0.978      0.982      0.903\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     30/140      32.3G     0.5469     0.3515     0.8205        144        640: 100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.35it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.972      0.977       0.98      0.882\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     31/140      32.6G     0.5569     0.3468     0.8257        174        640: 100%|██████████| 8/8 [00:04<00:00,  1.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.00it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.957      0.983      0.985      0.897\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     32/140      32.3G     0.5289     0.3323     0.8137        127        640: 100%|██████████| 8/8 [00:04<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.68it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.973      0.979      0.987      0.883\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     33/140      32.3G     0.5383     0.3411     0.8198        269        640: 100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.88it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.978      0.988      0.987      0.895\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     34/140      32.6G      0.528     0.3366     0.8174        139        640: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.90it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.947      0.972      0.984      0.904\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     35/140      32.5G     0.5193     0.3247     0.8112        209        640: 100%|██████████| 8/8 [00:04<00:00,  1.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.89it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.969      0.974       0.98      0.898\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     36/140      32.4G     0.5235       0.32     0.8195        219        640: 100%|██████████| 8/8 [00:04<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.54it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.984       0.98      0.981      0.901\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     37/140      32.3G     0.5333     0.3309     0.8192        208        640: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.52it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.984      0.974      0.985      0.893\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     38/140      32.3G     0.5226     0.3288     0.8157        193        640: 100%|██████████| 8/8 [00:04<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.35it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.975      0.976      0.983      0.906\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     39/140      32.4G     0.5097     0.3226     0.8101        248        640: 100%|██████████| 8/8 [00:04<00:00,  1.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.22it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.977      0.977      0.984      0.911\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     40/140      32.6G      0.516     0.3272     0.8245        130        640: 100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.99it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.961      0.983      0.983      0.899\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     41/140      32.4G     0.5141      0.311     0.8178        154        640: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.99it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.978      0.983      0.987      0.907\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     42/140      32.4G      0.492     0.3017      0.811        155        640: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.24it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238       0.98      0.983      0.986      0.911\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     43/140      32.4G     0.4948     0.3024     0.8114        241        640: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.00it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.977      0.985      0.987       0.91\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     44/140      32.6G     0.4974     0.3118     0.8177        183        640: 100%|██████████| 8/8 [00:04<00:00,  1.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.00it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.968      0.977      0.984       0.91\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     45/140      32.4G     0.5037      0.309     0.8151        251        640: 100%|██████████| 8/8 [00:04<00:00,  1.95it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.02it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.983      0.982      0.986      0.909\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     46/140      32.3G     0.4951     0.3044     0.8116        158        640: 100%|██████████| 8/8 [00:04<00:00,  1.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.01it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.981      0.984      0.985      0.915\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     47/140      32.3G     0.5025     0.3021     0.8085        139        640: 100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.99it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.981      0.974      0.985      0.911\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     48/140      32.3G     0.4986     0.3072     0.8119        218        640: 100%|██████████| 8/8 [00:04<00:00,  1.95it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.97it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.979      0.967      0.984      0.911\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     49/140      32.7G     0.4997     0.3046     0.8147        282        640: 100%|██████████| 8/8 [00:04<00:00,  1.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.90it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238       0.98      0.968      0.985      0.917\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     50/140      32.3G     0.4932     0.3009     0.8125        155        640: 100%|██████████| 8/8 [00:04<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.35it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238       0.98      0.974      0.987      0.917\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     51/140      32.3G     0.5003     0.2933      0.815        201        640: 100%|██████████| 8/8 [00:04<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.94it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.979      0.971      0.987      0.919\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     52/140      32.7G     0.4988     0.2974     0.8165        209        640: 100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.24it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.982       0.98      0.987      0.912\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     53/140      32.8G     0.4859     0.3019      0.815        181        640: 100%|██████████| 8/8 [00:04<00:00,  1.95it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.06it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.984      0.991      0.986      0.909\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     54/140      32.7G     0.4813     0.2845     0.8064        242        640: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.92it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.975      0.983      0.982       0.91\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     55/140      32.3G     0.4931      0.301     0.8109        318        640: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.74it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.975      0.992      0.983      0.914\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     56/140      32.8G     0.4758     0.2846     0.8075        176        640: 100%|██████████| 8/8 [00:04<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.00it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.979       0.99      0.983      0.916\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     57/140      32.3G     0.4742     0.2883     0.8168        207        640: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.94it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.978       0.99      0.982       0.91\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     58/140      32.5G     0.4689     0.2817     0.8092        230        640: 100%|██████████| 8/8 [00:04<00:00,  1.90it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.62it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.981      0.976      0.982      0.914\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     59/140      32.4G     0.4679     0.2793     0.8052         98        640: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.97it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.983      0.975      0.983      0.914\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     60/140      32.3G     0.4667     0.2733     0.8154        176        640: 100%|██████████| 8/8 [00:04<00:00,  1.96it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.94it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.983      0.984       0.98      0.913\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     61/140      32.4G     0.4699     0.2767     0.8057        198        640: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.79it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.982      0.975      0.986      0.914\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     62/140      32.6G     0.4671     0.2734      0.807        219        640: 100%|██████████| 8/8 [00:04<00:00,  1.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.03it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.983      0.977      0.988      0.925\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     63/140      32.3G     0.4566     0.2745     0.7976        180        640: 100%|██████████| 8/8 [00:04<00:00,  1.88it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.08it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.985      0.975      0.988      0.924\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     64/140      32.4G     0.4566     0.2763     0.8111        203        640: 100%|██████████| 8/8 [00:04<00:00,  1.96it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.11it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.974      0.975      0.987      0.924\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     65/140      32.3G     0.4529     0.2731     0.8094        226        640: 100%|██████████| 8/8 [00:04<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.16it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.972      0.977      0.986      0.919\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     66/140      32.4G     0.4584     0.2721     0.8084        146        640: 100%|██████████| 8/8 [00:04<00:00,  1.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.05it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.979       0.99      0.988      0.918\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     67/140      32.4G     0.4398     0.2706     0.8049        152        640: 100%|██████████| 8/8 [00:04<00:00,  1.95it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.978      0.989      0.987      0.928\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     68/140      32.5G      0.454     0.2699     0.8055        153        640: 100%|██████████| 8/8 [00:04<00:00,  1.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.55it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.973      0.989      0.987      0.927\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     69/140      32.6G     0.4569      0.272     0.8128        131        640: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.81it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.981       0.99      0.988      0.924\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     70/140      32.5G      0.445     0.2602      0.799        233        640: 100%|██████████| 8/8 [00:04<00:00,  1.96it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.99it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.981      0.992      0.988       0.93\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     71/140      32.7G     0.4423     0.2653     0.8066        145        640: 100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.94it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.983      0.992      0.987      0.924\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     72/140      32.8G     0.4535     0.2696      0.805        154        640: 100%|██████████| 8/8 [00:04<00:00,  1.90it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.03it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.976      0.983      0.987      0.928\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     73/140      32.3G      0.454     0.2604     0.8041        283        640: 100%|██████████| 8/8 [00:04<00:00,  1.95it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.13it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.979      0.986      0.988      0.919\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     74/140      32.6G     0.4384     0.2558     0.8084        238        640: 100%|██████████| 8/8 [00:04<00:00,  1.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.05it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.982      0.992      0.988       0.92\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     75/140      32.7G     0.4261     0.2527     0.8013        125        640: 100%|██████████| 8/8 [00:04<00:00,  1.96it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.92it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.982      0.975      0.988      0.925\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     76/140      32.6G     0.4165     0.2486     0.7969        166        640: 100%|██████████| 8/8 [00:04<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.74it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.985      0.978      0.988      0.927\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     77/140      32.4G     0.4198     0.2545     0.8025        233        640: 100%|██████████| 8/8 [00:04<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.01it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.985      0.992      0.988      0.928\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     78/140      32.6G     0.4285     0.2551     0.8059        237        640: 100%|██████████| 8/8 [00:04<00:00,  1.90it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.97it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.981      0.992      0.988      0.928\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     79/140      32.7G     0.4158     0.2565     0.8031        124        640: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.90it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.982      0.989      0.987      0.923\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     80/140      32.3G     0.4231     0.2514     0.8023        130        640: 100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.94it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.982      0.992      0.987      0.932\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     81/140      32.6G     0.4284     0.2562     0.7991        262        640: 100%|██████████| 8/8 [00:04<00:00,  1.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.94it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.978      0.982      0.987      0.931\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     82/140      32.3G     0.4136     0.2449     0.8052        212        640: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.36it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.968      0.978      0.986      0.934\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     83/140      32.7G     0.4112     0.2499     0.8014        220        640: 100%|██████████| 8/8 [00:04<00:00,  1.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.80it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238       0.98      0.987      0.988      0.928\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     84/140      32.4G     0.4071     0.2465     0.7994        182        640: 100%|██████████| 8/8 [00:04<00:00,  1.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.17it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.985      0.987      0.989      0.934\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     85/140      32.5G     0.4023     0.2369     0.7933        184        640: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.11it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238       0.98      0.986      0.988      0.932\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     86/140      32.3G     0.4213     0.2487      0.801        214        640: 100%|██████████| 8/8 [00:04<00:00,  1.89it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.06it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.983      0.987      0.988      0.927\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     87/140      32.5G     0.4167     0.2503     0.8039        145        640: 100%|██████████| 8/8 [00:04<00:00,  1.96it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.36it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.982      0.985      0.988      0.926\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     88/140      32.6G     0.4189     0.2487     0.7992        159        640: 100%|██████████| 8/8 [00:04<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.93it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.986      0.983      0.988      0.938\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     89/140      32.4G     0.4214     0.2467     0.8003        182        640: 100%|██████████| 8/8 [00:04<00:00,  1.90it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.00it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.986      0.992      0.988      0.937\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     90/140      32.3G     0.4168     0.2481     0.8033        165        640: 100%|██████████| 8/8 [00:04<00:00,  1.98it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.44it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.979      0.989      0.988      0.937\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     91/140      32.3G     0.3881     0.2316     0.8011        129        640: 100%|██████████| 8/8 [00:04<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.00it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.975       0.99      0.988      0.932\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     92/140      32.4G     0.3995     0.2498     0.8011        161        640: 100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.94it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238       0.98      0.992      0.988      0.928\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     93/140      32.4G     0.3913      0.235     0.7976        191        640: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.95it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.986      0.992      0.987       0.93\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     94/140      32.7G     0.3964     0.2461     0.7933        286        640: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.00it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.986      0.929\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     95/140      32.3G     0.3919     0.2353     0.7994        153        640: 100%|██████████| 8/8 [00:04<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.86it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.986      0.992      0.988      0.934\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     96/140      32.4G     0.3853     0.2286     0.7934        129        640: 100%|██████████| 8/8 [00:04<00:00,  1.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.23it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.985      0.982      0.985      0.928\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     97/140      32.4G     0.3871     0.2316     0.7992        220        640: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.12it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.986      0.983      0.985      0.938\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     98/140      32.7G     0.3861     0.2365     0.7978        167        640: 100%|██████████| 8/8 [00:04<00:00,  1.88it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.53it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.983      0.988      0.989       0.94\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     99/140      32.3G      0.388     0.2366     0.8014        124        640: 100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.02it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.985       0.99      0.988      0.939\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    100/140      32.8G     0.3807     0.2307     0.7934        165        640: 100%|██████████| 8/8 [00:04<00:00,  1.89it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.99it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.986      0.992      0.988      0.941\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    101/140      32.5G     0.3781     0.2308     0.7932        102        640: 100%|██████████| 8/8 [00:04<00:00,  1.89it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.06it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.986      0.992      0.989      0.944\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    102/140      32.3G     0.3895     0.2328        0.8        137        640: 100%|██████████| 8/8 [00:04<00:00,  1.89it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.05it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.989      0.942\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    103/140      32.6G      0.382     0.2303     0.7965        206        640: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.07it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.989      0.942\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    104/140      32.5G     0.3657     0.2176      0.797        185        640: 100%|██████████| 8/8 [00:04<00:00,  1.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.89it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.988      0.944\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    105/140      32.5G     0.3673     0.2229     0.7964        154        640: 100%|██████████| 8/8 [00:04<00:00,  1.89it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.92it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.989      0.941\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    106/140      32.3G     0.3741     0.2244     0.7957        202        640: 100%|██████████| 8/8 [00:04<00:00,  1.90it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.24it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.989      0.945\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    107/140      32.5G     0.3751      0.231     0.7993        166        640: 100%|██████████| 8/8 [00:04<00:00,  1.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.24it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.988      0.942\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    108/140      32.7G     0.3662     0.2217     0.7958        181        640: 100%|██████████| 8/8 [00:04<00:00,  1.89it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.85it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.988      0.942\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    109/140      32.3G     0.3583     0.2172     0.7966        167        640: 100%|██████████| 8/8 [00:04<00:00,  1.95it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.02it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.988      0.943\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    110/140      32.7G     0.3551     0.2205      0.795        166        640: 100%|██████████| 8/8 [00:04<00:00,  1.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.77it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.989      0.944\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    111/140      32.8G     0.3658     0.2195     0.7896        196        640: 100%|██████████| 8/8 [00:04<00:00,  1.90it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.92it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.988      0.942\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    112/140      32.5G     0.3492     0.2179     0.7938        149        640: 100%|██████████| 8/8 [00:04<00:00,  1.95it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.05it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.988      0.941\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    113/140      32.5G      0.356     0.2195     0.7946        169        640: 100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.06it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.985      0.992      0.988      0.939\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    114/140      32.4G     0.3534     0.2145      0.798        135        640: 100%|██████████| 8/8 [00:04<00:00,  1.90it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.77it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.989      0.945\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    115/140      32.8G     0.3488     0.2141     0.7907        189        640: 100%|██████████| 8/8 [00:04<00:00,  1.90it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.05it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.983      0.989      0.989      0.943\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    116/140      32.3G     0.3499     0.2131     0.7954        137        640: 100%|██████████| 8/8 [00:04<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.06it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.983      0.986      0.988      0.942\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    117/140      32.6G     0.3551     0.2191     0.7934        206        640: 100%|██████████| 8/8 [00:04<00:00,  1.88it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.81it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.989      0.944\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    118/140      32.7G     0.3431     0.2083     0.7922        180        640: 100%|██████████| 8/8 [00:04<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.15it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.986      0.992      0.989      0.941\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    119/140      32.3G     0.3506     0.2146     0.7981        183        640: 100%|██████████| 8/8 [00:04<00:00,  1.89it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.80it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.986      0.992      0.989      0.943\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    120/140      32.3G     0.3484     0.2108     0.7937        151        640: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.92it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.986      0.992      0.989      0.947\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    121/140      32.6G     0.3397     0.2063     0.7914        147        640: 100%|██████████| 8/8 [00:04<00:00,  1.88it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.94it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.989      0.942\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    122/140      32.3G     0.3397     0.2064     0.7901        164        640: 100%|██████████| 8/8 [00:04<00:00,  1.89it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.73it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.988      0.946\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    123/140      32.6G     0.3393     0.2065     0.7875        172        640: 100%|██████████| 8/8 [00:04<00:00,  1.89it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.96it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.989      0.944\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    124/140      32.4G     0.3296      0.202     0.7852        279        640: 100%|██████████| 8/8 [00:04<00:00,  1.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.88it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.989      0.948\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    125/140      32.5G     0.3348     0.2053     0.7883        207        640: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.13it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.989      0.948\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    126/140      32.5G     0.3339     0.2046     0.7851        195        640: 100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.82it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.989      0.947\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    127/140      32.7G     0.3375     0.2095     0.7886        216        640: 100%|██████████| 8/8 [00:04<00:00,  1.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.94it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.989      0.947\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    128/140      32.3G     0.3279     0.2004     0.7866        100        640: 100%|██████████| 8/8 [00:04<00:00,  1.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.03it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.988      0.992      0.989      0.947\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    129/140      32.6G     0.3292     0.2023     0.7866        193        640: 100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.94it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.989      0.949\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    130/140      32.5G     0.3318     0.2043     0.7855        157        640: 100%|██████████| 8/8 [00:04<00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.01it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.989      0.948\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    131/140      32.3G     0.3191     0.1871     0.7883         76        640: 100%|██████████| 8/8 [00:46<00:00,  5.87s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.07it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.989      0.939\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    132/140      32.6G     0.3031     0.1797     0.7822         57        640: 100%|██████████| 8/8 [00:32<00:00,  4.05s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.81it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992       0.99       0.95\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    133/140      32.6G     0.3028     0.1806     0.7747        194        640: 100%|██████████| 8/8 [00:24<00:00,  3.06s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.95it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.989      0.947\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    134/140      32.3G     0.2849     0.1702     0.7797        172        640: 100%|██████████| 8/8 [00:24<00:00,  3.11s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.91it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.989       0.95\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    135/140      32.6G     0.2948     0.1732     0.7862         98        640: 100%|██████████| 8/8 [00:17<00:00,  2.21s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.94it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.989      0.948\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    136/140      32.7G      0.284     0.1677     0.7834        128        640: 100%|██████████| 8/8 [00:22<00:00,  2.83s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.79it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.989      0.947\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    137/140      32.3G     0.2776     0.1689     0.7815        148        640: 100%|██████████| 8/8 [00:11<00:00,  1.46s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.06it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.989      0.949\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    138/140      32.3G     0.2838     0.1683     0.7779         41        640: 100%|██████████| 8/8 [00:12<00:00,  1.62s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.89it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.989      0.947\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    139/140      32.6G     0.2829     0.1725      0.781        145        640: 100%|██████████| 8/8 [00:13<00:00,  1.73s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.78it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.989      0.948\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    140/140      32.7G     0.2719     0.1639     0.7744        106        640: 100%|██████████| 8/8 [00:11<00:00,  1.39s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.89it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.989      0.949\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","140 epochs completed in 0.385 hours.\n","Optimizer stripped from yolovs_extra_chess_new/train/weights/last.pt, 40.5MB\n","Optimizer stripped from yolovs_extra_chess_new/train/weights/best.pt, 40.5MB\n","\n","Validating yolovs_extra_chess_new/train/weights/best.pt...\n","Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n","YOLO11m summary (fused): 303 layers, 20,039,284 parameters, 0 gradients, 67.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.992      0.989       0.95\n","           white-queen         10         16      0.996          1      0.995      0.962\n","            white-pawn         11         37      0.999          1      0.995      0.933\n","            black-rook          7         14      0.995          1      0.995      0.958\n","          black-bishop         12         22      0.997          1      0.995      0.962\n","          black-knight          6         10      0.993        0.9      0.933      0.918\n","           black-queen         15         24      0.997          1      0.995      0.986\n","            black-pawn         10         39      0.998          1      0.995      0.943\n","            black-king          8          8      0.884          1      0.982      0.967\n","            white-rook         11         20      0.997          1      0.995      0.903\n","          white-bishop         11         19      0.997          1      0.995      0.956\n","          white-knight          9         18      0.997          1      0.995       0.97\n","            white-king         11         11      0.994          1      0.995      0.938\n","Speed: 0.1ms preprocess, 1.3ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1myolovs_extra_chess_new/train\u001b[0m\n"]}],"execution_count":null},{"cell_type":"code","source":"# shutil.copytree('/content/yolo_extra_chess_detect', '/content/drive/MyDrive/CU/Dig_Img_Proc/project/yolo11m_extra_chess_detect_140eps')","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"J_M2vedfi9AF","outputId":"e6a11706-d623-4322-dcf9-b3f83d7683d5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/CU/Dig_Img_Proc/project/yolovs_extra_chess_140eps'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}],"execution_count":null},{"cell_type":"markdown","source":"## Model Evaluation","metadata":{"id":"68q15miN3_9C"}},{"cell_type":"code","source":"ultralytics.checks()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lE9VgEf58EZB","outputId":"54c3938c-97ce-49a6-8efc-467a622b9687"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n","Setup complete ✅ (2 CPUs, 12.7 GB RAM, 32.6/225.8 GB disk)\n"]}],"execution_count":null},{"cell_type":"code","source":"models = [\n    # {\n    #     \"name\": \"base_yolo11m\",\n    #     \"model\": YOLO('yolo11m.pt')\n    # },\n    {\n        \"name\": \"yolo11m_chess_detect_30eps\",\n        \"model\": YOLO(\"/content/drive/MyDrive/CU/Dig_Img_Proc/project/yolo11m_chess_detect_30eps/train/weights/best.pt\")\n    },\n    {\n        \"name\": \"yolo11m_extra_chess_detect_140eps\",\n        \"model\": YOLO(\"/content/drive/MyDrive/CU/Dig_Img_Proc/project/yolo11m_extra_chess_detect_140eps/train/weights/best.pt\")\n    }\n]","metadata":{"id":"C9Z-QRIH4Abe"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Root_dir = '/content/drive/MyDrive/CU/Dig_Img_Proc/project/extra_chess_data'\nyaml_path = os.path.join(Root_dir, 'data.yaml')\nwith open(yaml_path, 'r') as f:\n    print(f.read())\ntrain_path = os.path.join(Root_dir, 'train', 'images')\nvalid_path = os.path.join(Root_dir, 'valid', 'images')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wtwi2VxjYaTc","outputId":"8b0ea352-774c-4142-a70f-67e3d9b0a1ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["path: /content/drive/MyDrive/CU/Dig_Img_Proc/project/extra_chess_data\n","\n","train: train/images\n","val: valid/images\n","test: test/images\n","\n","names: \n","  0: white-queen\n","  1: white-pawn\n","  2: black-rook\n","  3: black-bishop\n","  4: black-knight\n","  5: black-queen\n","  6: black-pawn\n","  7: black-king\n","  8: white-rook\n","  9: white-bishop\n","  10: white-knight\n","  11: white-king\n"]}],"execution_count":null},{"cell_type":"code","source":"# dataset: https://public.roboflow.com/object-detection/chess-full/\n\nfor model in models:\n    results = model[\"model\"].val(\n        data=yaml_path,\n        batch=48,\n        imgsz=736,\n        plots=True,\n        project=model[\"name\"],\n        name=model[\"name\"]\n    )","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pANGBobR94k8","outputId":"8831893a-5128-4d5b-8b8b-e8cbf2a76451"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n","YOLO11m summary (fused): 303 layers, 20,039,284 parameters, 0 gradients, 67.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/CU/Dig_Img_Proc/project/extra_chess_data/valid/labels.cache... 60 images, 0 backgrounds, 0 corrupt: 100%|██████████| 60/60 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [04:34<00:00, 137.25s/it]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238     0.0418      0.341     0.0473     0.0265\n","          black-bishop         10         16          0          0          0          0\n","            black-king         11         37          0          0          0          0\n","          black-knight          7         14     0.0897      0.929      0.124     0.0614\n","            black-pawn         12         22     0.0674      0.545     0.0703     0.0311\n","           black-queen          6         10     0.0426        0.4     0.0298     0.0121\n","            black-rook         15         24     0.0798      0.542      0.125     0.0564\n","          white-bishop         10         39          0          0          0          0\n","            white-king          8          8          0          0          0          0\n","          white-knight         11         20      0.106       0.75      0.126     0.0863\n","            white-pawn         11         19     0.0661      0.421     0.0547     0.0442\n","           white-queen          9         18      0.013     0.0556    0.00804    0.00161\n","            white-rook         11         11     0.0376      0.455     0.0295     0.0251\n","Speed: 14.8ms preprocess, 2370.8ms inference, 0.0ms loss, 1.2ms postprocess per image\n","Results saved to \u001b[1myolo11m_chess_detect_30eps/yolo11m_chess_detect_30eps4\u001b[0m\n","Ultralytics 8.3.40 🚀 Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n","YOLO11m summary (fused): 303 layers, 20,039,284 parameters, 0 gradients, 67.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/CU/Dig_Img_Proc/project/extra_chess_data/valid/labels.cache... 60 images, 0 backgrounds, 0 corrupt: 100%|██████████| 60/60 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [02:55<00:00, 87.60s/it]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         60        238      0.987      0.989      0.988      0.951\n","           white-queen         10         16      0.995          1      0.995      0.973\n","            white-pawn         11         37      0.999          1      0.995      0.925\n","            black-rook          7         14      0.994          1      0.995      0.964\n","          black-bishop         12         22      0.997          1      0.995      0.971\n","          black-knight          6         10      0.987        0.9      0.928      0.899\n","           black-queen         15         24      0.996          1      0.995      0.985\n","            black-pawn         10         39      0.998          1      0.995      0.931\n","            black-king          8          8      0.885          1      0.982      0.967\n","            white-rook         11         20          1          1      0.995      0.935\n","          white-bishop         11         19      0.997          1      0.995      0.928\n","          white-knight          9         18          1      0.965      0.995      0.987\n","            white-king         11         11      0.992          1      0.995       0.95\n","Speed: 6.8ms preprocess, 2377.0ms inference, 0.0ms loss, 1.1ms postprocess per image\n","Results saved to \u001b[1myolo11m_extra_chess_detect_140eps/yolo11m_extra_chess_detect_140eps2\u001b[0m\n"]}],"execution_count":null}]}